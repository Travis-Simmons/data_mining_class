{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "class data_test:\n",
    "\n",
    "    # this one does predictions \n",
    "    def make_predictions(X, thetas_list, type = 'linear', desicion_rule = 0.5):\n",
    "\n",
    "        if type == 'linear':\n",
    "            print('test')\n",
    "\n",
    "            prediction_list = []\n",
    "\n",
    "            for x in X:\n",
    "                prediction = x.dot(thetas_list)\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "            print('Predictions', prediction_list)\n",
    "            return prediction_list\n",
    "\n",
    "\n",
    "        if type == 'log':\n",
    "            # Prediction storage list\n",
    "            prediction_list = []\n",
    "\n",
    "            # Itterate through the data by observation\n",
    "            for x in X:\n",
    "\n",
    "                # Prediction is just dot product of Vector x and list of thetas\n",
    "                prediction = 1/(1+(math.e)**-(x.dot(thetas_list)))\n",
    "\n",
    "                # Store predictions\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "            rounded_list = []\n",
    "            for i in prediction_list:\n",
    "                if i > desicion_rule:\n",
    "                    rounded_list.append(1)\n",
    "                else:\n",
    "                    rounded_list.append(0)\n",
    "\n",
    "\n",
    "            print('Predictions', rounded_list)\n",
    "            return prediction_list\n",
    "\n",
    "    # this one does cost fuctions\n",
    "\n",
    "    def get_cost(thetas_list, inputs, outputs, type = 'log'):\n",
    "\n",
    "        if type == 'log':\n",
    "            print(f'Determining cost for thetas {thetas_list}...\\n')\n",
    "\n",
    "            # We will use this list to store all our errors for the summation\n",
    "            errors_list = []\n",
    "\n",
    "            cnt = 1\n",
    "            # Itterate through the data by observation\n",
    "            for x, y in zip(inputs,outputs):\n",
    "                \n",
    "                # Prediction is just dot product of Vector x and list of thetas\n",
    "                prediction = 1/(1+(math.e)**-(x.dot(thetas_list)))\n",
    "        \n",
    "\n",
    "                # Log error function\n",
    "                obs_error = -(((y*math.log(prediction, 10)) + ((1-y)*math.log(1-prediction, 10))))\n",
    "\n",
    "\n",
    "                errors_list.append(obs_error)\n",
    "\n",
    "                print(f'Prediction for observation {cnt}: {prediction}')\n",
    "            \n",
    "                print(f'Error for prediction: {errors_list[cnt-1]}\\n')\n",
    "                cnt += 1 \n",
    "\n",
    "            total_cost = ((1/len(outputs)) * sum(errors_list))\n",
    "\n",
    "            print(f'Total cost: {total_cost}.\\n')\n",
    "\n",
    "            return total_cost\n",
    "\n",
    "\n",
    "        if type == 'linear':\n",
    "            print(f'Determining cost for thetas {thetas_list}...\\n')\n",
    "\n",
    "            # We will use this list to store all our errors for the summation\n",
    "            errors_list = []\n",
    "\n",
    "            cnt = 1\n",
    "            # Itterate through the data by observation\n",
    "            for x, y in zip(inputs,outputs):\n",
    "                \n",
    "                # Prediction is just dot product of Vector x and list of thetas\n",
    "                prediction = x.dot(thetas_list)\n",
    "        \n",
    "\n",
    "                # Log error function\n",
    "                obs_error = (prediction-y)**2\n",
    "\n",
    "\n",
    "                errors_list.append(obs_error)\n",
    "\n",
    "                print(f'Prediction for observation {cnt}: {prediction}')\n",
    "            \n",
    "                print(f'Error for prediction: {errors_list[cnt-1]}\\n')\n",
    "                cnt += 1 \n",
    "\n",
    "            total_cost = ((1/(2*len(outputs))) * sum(errors_list))\n",
    "\n",
    "            print(f'Total cost: {total_cost}.\\n')\n",
    "\n",
    "            return total_cost\n",
    "\n",
    "    # This one does ne for thesa values\n",
    "    def get_ne(X, Y):\n",
    "        theta_NE = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)\n",
    "\n",
    "        print(\"NE gives\", theta_NE)\n",
    "\n",
    "    # this one does gd for theta values\n",
    "\n",
    "    def sig(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def gradient_descent( X, Y, learning_rate, itterations, theta_initials = 0, type = 'linear' ):\n",
    "        \n",
    "        theta = [theta_initials for i in X[0]]\n",
    "        theta_dict = {}\n",
    "                \n",
    "        cnt = 0\n",
    "        for i in theta:\n",
    "            theta_dict[f'theta{cnt}'] = 0\n",
    "            cnt += 1\n",
    "\n",
    "        if type == 'linear':\n",
    "            for i in range(itterations):\n",
    "                \n",
    "                # itterativly create a dictionary for the thetas so the function doesnt care about how many thetas you give\n",
    "                cnt = 0\n",
    "                for i in theta_dict:\n",
    "                    theta_dict[f'theta{cnt}'] -= learning_rate/len(X)*((X.dot(list(theta_dict.values()))-Y).dot(X[:,cnt]))\n",
    "                    cnt += 1\n",
    "\n",
    "            print(\"Linear GD gives\", theta_dict)\n",
    "        \n",
    "        if type == 'log':\n",
    "            for i in range(itterations):\n",
    "            \n",
    "                # itterativly create a dictionary for the thetas so the function doesnt care about how many thetas you give\n",
    "                cnt = 0\n",
    "                for i in theta_dict:\n",
    "                    theta_dict[f'theta{cnt}'] -= learning_rate/len(X)*((data_test.sig(X.dot(list(theta_dict.values())))-Y).dot(X[:,cnt]))\n",
    "\n",
    "                    cnt += 1\n",
    "\n",
    "            print(\"Logistic GD gives\", theta_dict)\n",
    "\n",
    "        return list(theta_dict.values())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Linear descent testing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,10,6,5,11],[1,4,8,9,3],[1,7,5,3,4],[1,16,10,8,9],[1,12,15,11,16], [1,5,9,6,8], [1,17,14,10,15]])\n",
    "Y = np.array([20,18,11,26,49,17,31])\n",
    "\n",
    "\n",
    "alpha = 0.001        # In class we chose 0.1 but it will not converge so here we use a smaller one.\n",
    "initial_thetas = [0,0,0,0,0]\n",
    "\n",
    "thetas_list = data_test.gradient_descent( X, Y, alpha, 30000, type = 'linear' )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear GD gives {'theta0': -3.7201712307816264, 'theta1': -0.276515454837906, 'theta2': 0.5332391767929376, 'theta3': 1.7045437971241677, 'theta4': 1.4158531970450685}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X = np.array([\n",
    "    [1,7,5],\n",
    "    [1,3,8],\n",
    "    [1,9,6],\n",
    "    [1,11,7]        \n",
    "])\n",
    "\n",
    "Y = np.array([\n",
    "    [14,15,10,16]\n",
    "])\n",
    "\n",
    "alpha = 0.001   \n",
    "\n",
    "\n",
    "thetas_list = data_test.gradient_descent( X, Y, alpha, 30000, type = 'linear' )"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (4,)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f547ba704951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mthetas_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-a1e658d2f768>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(X, Y, learning_rate, itterations, theta_initials, type)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtheta_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mtheta_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'theta{cnt}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                     \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (4,)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# linear ne testing\n",
    "\n",
    "data_test.get_ne(X,Y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NE gives [-3.91161916 -0.27150108  0.53569403  1.71997188  1.41405869]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Longitudinal descent testing\n",
    "\n",
    "X = np.array([[1,9,5,4,3],[1,4,7,9,2],[1,7,5,8,6],[1,6,4,5,3],[1,8,6,11,7],[1,5,9,6,8],[1,7,4,10,6],[1,6,5,3,10]])\n",
    "Y = np.array([1,1,0,0,1,0,0,1])\n",
    "\n",
    "alpha = 0.05\n",
    "initial_thetas = [0,0,0,0,0]\n",
    "iterrations = 50000\n",
    "\n",
    "thetas_list = data_test.gradient_descent( X, Y, alpha, iterrations, type = 'log' )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic GD gives {'theta0': -3.532944418583202, 'theta1': 0.44813730757372955, 'theta2': 0.35852722903853557, 'theta3': -0.1102581682182862, 'theta4': -0.10649289489030896}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "thetas_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-3.532944418583202,\n",
       " 0.44813730757372955,\n",
       " 0.35852722903853557,\n",
       " -0.1102581682182862,\n",
       " -0.10649289489030896]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# linear prediction\n",
    "import math\n",
    "\n",
    "\n",
    "X = np.array([\n",
    "    [1,4,2,1],\n",
    "    [1, 2,3.5,3],\n",
    "    [1,3,4,4],\n",
    "    [1,5,4,3],\n",
    "    [1,2,2,2]\n",
    "])\n",
    "\n",
    "# Given thetas\n",
    "thetas_list = [-10, 4, 3, -5]\n",
    "\n",
    "predictions = data_test.make_predictions(X, thetas_list, type = 'log')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions [1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "predictions = data_test.make_predictions(X, thetas_list, type = 'linear')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test\n",
      "Predictions [7.0, -6.5, -6.0, 7.0, -6.0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\n",
    "X = np.array([[1,9,5,4,3],[1,4,7,9,2],[1,7,5,8,6],[1,6,4,5,3],[1,8,6,11,7],[1,5,9,6,8],[1,7,4,10,6],[1,6,5,3,10]])\n",
    "Y = np.array([1,1,0,0,1,0,0,1])\n",
    "\n",
    "theta_list = data_test.gradient_descent( X, Y, alpha, iterrations, type = 'log' )\n",
    "print(theta_list)\n",
    "\n",
    "linear_cost = data_test.get_cost(theta_list, X, Y, 'log')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic GD gives {'theta0': -3.532944418583202, 'theta1': 0.44813730757372955, 'theta2': 0.35852722903853557, 'theta3': -0.1102581682182862, 'theta4': -0.10649289489030896}\n",
      "[-3.532944418583202, 0.44813730757372955, 0.35852722903853557, -0.1102581682182862, -0.10649289489030896]\n",
      "Determining cost for thetas [-3.532944418583202, 0.44813730757372955, 0.35852722903853557, -0.1102581682182862, -0.10649289489030896]...\n",
      "\n",
      "Prediction for observation 1: 0.8223595489310899\n",
      "Error for prediction: 0.08493826034791932\n",
      "\n",
      "Prediction for observation 2: 0.39269118856053226\n",
      "Error for prediction: 0.40594884357926775\n",
      "\n",
      "Prediction for observation 3: 0.46894755704576224\n",
      "Error for prediction: 0.27486258897310534\n",
      "\n",
      "Prediction for observation 4: 0.43026226911633997\n",
      "Error for prediction: 0.24432501843700616\n",
      "\n",
      "Prediction for observation 5: 0.5609521743070042\n",
      "Error for prediction: 0.2510741642696132\n",
      "\n",
      "Prediction for observation 6: 0.6037213230116674\n",
      "Error for prediction: 0.40199929560788544\n",
      "\n",
      "Prediction for observation 7: 0.3310558678570606\n",
      "Error for prediction: 0.1746101514626602\n",
      "\n",
      "Prediction for observation 8: 0.39002958006681687\n",
      "Error for prediction: 0.4089024545821183\n",
      "\n",
      "Total cost: 0.28083259715744696.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "method_list = [func for func in dir(data_test) if callable(getattr(data_test, func))]\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X = np.array([[1,2.5], [1,4.6], [1,7], [1,9], [1,12]])\n",
    "Y = np.array([3, 5, 4, 8,10])\n",
    "\n",
    "data_test.get_ne(X,Y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NE gives [0.90804974 0.72534904]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X = np.array([\n",
    "    [1,7,5],\n",
    "    [1,3,8],\n",
    "    [1,9,6],\n",
    "    [1,11,7]        \n",
    "])\n",
    "\n",
    "Y = np.array(\n",
    "    [14,15,10,16]\n",
    ")\n",
    "\n",
    "data_test.get_ne(X,Y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NE gives [7.43333333 0.03333333 0.93333333]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Problem 4\n",
    "import math\n",
    "X = np.array([\n",
    "    [1,9,8],\n",
    "    [1,4,4],\n",
    "    [1,7,6],\n",
    "    [1,3,5],\n",
    "    [1,8,6]\n",
    "])\n",
    "\n",
    "Y = np.array([1,1,0,0,1])\n",
    "\n",
    "\n",
    "# find cost\n",
    "austin_thetas = [2,3,-2]\n",
    "victor_thetas = [1,2,-2]\n",
    "\n",
    "austin_cost = data_test.get_cost(austin_thetas, X, Y, type = 'log')\n",
    "victor_cost = data_test.get_cost(victor_thetas, X, Y, type = 'log')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Determining cost for thetas [2, 3, -2]...\n",
      "\n",
      "Prediction for observation 1: 0.999997739675702\n",
      "Error for prediction: 9.816474793343027e-07\n",
      "\n",
      "Prediction for observation 2: 0.9975273768433653\n",
      "Error for prediction: 0.001075176394246175\n",
      "\n",
      "Prediction for observation 3: 0.999983298578152\n",
      "Error for prediction: 4.777246554335378\n",
      "\n",
      "Prediction for observation 4: 0.7310585786300049\n",
      "Error for prediction: 0.5703423041841167\n",
      "\n",
      "Prediction for observation 5: 0.9999991684719722\n",
      "Error for prediction: 3.6112818415126625e-07\n",
      "\n",
      "Total cost: 1.0697330755378809.\n",
      "\n",
      "Determining cost for thetas [1, 2, -2]...\n",
      "\n",
      "Prediction for observation 1: 0.9525741268224331\n",
      "Error for prediction: 0.021101218678769487\n",
      "\n",
      "Prediction for observation 2: 0.7310585786300049\n",
      "Error for prediction: 0.13604782228086493\n",
      "\n",
      "Prediction for observation 3: 0.9525741268224331\n",
      "Error for prediction: 1.323984664388524\n",
      "\n",
      "Prediction for observation 4: 0.04742587317756679\n",
      "Error for prediction: 0.021101218678769434\n",
      "\n",
      "Prediction for observation 5: 0.9933071490757153\n",
      "Error for prediction: 0.0029164387928812623\n",
      "\n",
      "Total cost: 0.3010302725639618.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(austin_cost)\n",
    "\n",
    "\n",
    "print(victor_cost)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0697330755378809\n",
      "0.3010302725639618\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "new_thetas = data_test.gradient_descent(X, Y, 0.001, 500000, type = 'log')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic GD gives {'theta0': 1.3102029621175617, 'theta1': 1.1601673417979272, 'theta2': -1.3915199246711998}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# problem 3c\n",
    "\n",
    "X = np.array([\n",
    "    [1,1,3],\n",
    "    [1,5,4],\n",
    "    [1,9,2]\n",
    "])\n",
    "predictions = data_test.make_predictions(X, new_thetas, type = 'log')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions [0, 1, 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "predictions"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.15391888795073272, 0.8241846028164896, 0.9998726786711339]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "dict_1 = {'thing':1, 'other_thing':2}\n",
    "dict_2 = {'thing':3, 'other_thing':4}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "dict_1['thing'] = 5\n",
    "dict_1['other_thing'] = 6"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "dict_1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'thing': 5, 'other_thing': 6}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "dict_2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'thing': 3, 'other_thing': 4}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "dict_2 = dict_1.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "dict_2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'thing': 5, 'other_thing': 6}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "dict_1['thing'] = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "dict_2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'thing': 5, 'other_thing': 6}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import test_1_functions as tf\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "X = np.array([[1,2.5], [1,4.6], [1,7], [1,9], [1,12]])\n",
    "Y = np.array([3, 5, 4, 8,10])\n",
    "\n",
    "tf.data_test.gradient_descent(X, Y, 0.001, 1, type = 'linear')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear GD gives {'theta0': -0.006, 'theta1': -0.050100000000000006}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-0.006, -0.050100000000000006]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import test_1_functions as tf\n",
    "X = np.array([[1,5,7,12],[1,4,3,2],[1,11,14,6],[1,8,7,1],[1,9,6,4],[1,3,5,9]])\n",
    "Y = np.array([11,24,17,16,9,10])\n",
    "\n",
    "tf.data_test.gradient_descent(X, Y, 0.001, 50000, regularization=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Regularized linear GD gives {'theta0': 17.054710293629643, 'theta1': -0.07811903267888685, 'theta2': 0.012287681817201112, 'theta3': -0.3741299351358906}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[17.054710293629643,\n",
       " -0.07811903267888685,\n",
       " 0.012287681817201112,\n",
       " -0.3741299351358906]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "tf.data_test.get_ne(X, Y, regularization = True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Regularized NE gives [ 1.70553981e+01 -7.81534101e-02  1.22643970e-02 -3.74157553e-01]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NE gives [ 1.70553981e+01 -7.81534101e-02  1.22643970e-02 -3.74157553e-01]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('general': conda)"
  },
  "interpreter": {
   "hash": "56a448c051c34e45e9834b3bc424179772d4669d3cb935d3f78ef5964f2ca1f5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}