{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class data_test:\n",
    "\n",
    "    # this one does predictions \n",
    "    def make_predictions(X, thetas_list, type = 'linear', desicion_rule = 0.5):\n",
    "\n",
    "        if type == 'linear':\n",
    "            print('test')\n",
    "\n",
    "            prediction_list = []\n",
    "\n",
    "            for x in X:\n",
    "                prediction = x.dot(thetas_list)\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "            print('Predictions', prediction_list)\n",
    "            return prediction_list\n",
    "\n",
    "\n",
    "        if type == 'log':\n",
    "            # Prediction storage list\n",
    "            prediction_list = []\n",
    "\n",
    "            # Itterate through the data by observation\n",
    "            for x in X:\n",
    "\n",
    "                # Prediction is just dot product of Vector x and list of thetas\n",
    "                prediction = 1/(1+(math.e)**-(x.dot(thetas_list)))\n",
    "\n",
    "                # Store predictions\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "            rounded_list = []\n",
    "            for i in prediction_list:\n",
    "                if i > desicion_rule:\n",
    "                    rounded_list.append(1)\n",
    "                else:\n",
    "                    rounded_list.append(0)\n",
    "\n",
    "\n",
    "            print('Predictions', rounded_list)\n",
    "            return rounded_list\n",
    "\n",
    "    # this one does cost fuctions\n",
    "\n",
    "    def get_cost(thetas_list, inputs, outputs, type = 'log'):\n",
    "\n",
    "        if type == 'log':\n",
    "            print(f'Determining cost for thetas {thetas_list}...\\n')\n",
    "\n",
    "            # We will use this list to store all our errors for the summation\n",
    "            errors_list = []\n",
    "\n",
    "            cnt = 1\n",
    "            # Itterate through the data by observation\n",
    "            for x, y in zip(inputs,outputs):\n",
    "                \n",
    "                # Prediction is just dot product of Vector x and list of thetas\n",
    "                prediction = 1/(1+(math.e)**-(x.dot(thetas_list)))\n",
    "        \n",
    "\n",
    "                # Log error function\n",
    "                obs_error = -(((y*math.log(prediction, 10)) + ((1-y)*math.log(1-prediction, 10))))\n",
    "\n",
    "\n",
    "                errors_list.append(obs_error)\n",
    "\n",
    "                print(f'Prediction for observation {cnt}: {prediction}')\n",
    "            \n",
    "                print(f'Error for prediction: {errors_list[cnt-1]}\\n')\n",
    "                cnt += 1 \n",
    "\n",
    "            total_cost = ((1/len(outputs)) * sum(errors_list))\n",
    "\n",
    "            print(f'Total cost: {total_cost}.\\n')\n",
    "\n",
    "            return total_cost\n",
    "\n",
    "\n",
    "        if type == 'linear':\n",
    "            print(f'Determining cost for thetas {thetas_list}...\\n')\n",
    "\n",
    "            # We will use this list to store all our errors for the summation\n",
    "            errors_list = []\n",
    "\n",
    "            cnt = 1\n",
    "            # Itterate through the data by observation\n",
    "            for x, y in zip(inputs,outputs):\n",
    "                \n",
    "                # Prediction is just dot product of Vector x and list of thetas\n",
    "                prediction = x.dot(thetas_list)\n",
    "        \n",
    "\n",
    "                # Log error function\n",
    "                obs_error = (prediction-y)**2\n",
    "\n",
    "\n",
    "                errors_list.append(obs_error)\n",
    "\n",
    "                print(f'Prediction for observation {cnt}: {prediction}')\n",
    "            \n",
    "                print(f'Error for prediction: {errors_list[cnt-1]}\\n')\n",
    "                cnt += 1 \n",
    "\n",
    "            total_cost = ((1/(2*len(outputs))) * sum(errors_list))\n",
    "\n",
    "            print(f'Total cost: {total_cost}.\\n')\n",
    "\n",
    "            return total_cost\n",
    "\n",
    "    # This one does ne for thesa values\n",
    "    def get_ne(X, Y):\n",
    "        theta_NE = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)\n",
    "\n",
    "        print(\"NE gives\", theta_NE)\n",
    "\n",
    "    # this one does gd for theta values\n",
    "\n",
    "    def sig(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def gradient_descent( X, Y, learning_rate, itterations, theta_initials = 0, type = 'linear' ):\n",
    "        \n",
    "        theta = [theta_initials for i in X[0]]\n",
    "        theta_dict = {}\n",
    "                \n",
    "        cnt = 0\n",
    "        for i in theta:\n",
    "            theta_dict[f'theta{cnt}'] = 0\n",
    "            cnt += 1\n",
    "\n",
    "        if type == 'linear':\n",
    "            for i in range(itterations):\n",
    "                \n",
    "                # itterativly create a dictionary for the thetas so the function doesnt care about how many thetas you give\n",
    "                cnt = 0\n",
    "                for i in theta_dict:\n",
    "                    theta_dict[f'theta{cnt}'] -= learning_rate/len(X)*((X.dot(list(theta_dict.values()))-Y).dot(X[:,cnt]))\n",
    "                    cnt += 1\n",
    "\n",
    "            print(\"Linear GD gives\", theta_dict)\n",
    "        \n",
    "        if type == 'log':\n",
    "            for i in range(itterations):\n",
    "            \n",
    "                # itterativly create a dictionary for the thetas so the function doesnt care about how many thetas you give\n",
    "                cnt = 0\n",
    "                for i in theta_dict:\n",
    "                    theta_dict[f'theta{cnt}'] -= learning_rate/len(X)*((data_test.sig(X.dot(list(theta_dict.values())))-Y).dot(X[:,cnt]))\n",
    "\n",
    "                    cnt += 1\n",
    "\n",
    "            print(\"Logistic GD gives\", theta_dict)\n",
    "\n",
    "        return list(theta_dict.values())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Linear descent testing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,10,6,5,11],[1,4,8,9,3],[1,7,5,3,4],[1,16,10,8,9],[1,12,15,11,16], [1,5,9,6,8], [1,17,14,10,15]])\n",
    "Y = np.array([20,18,11,26,49,17,31])\n",
    "\n",
    "\n",
    "alpha = 0.001        # In class we chose 0.1 but it will not converge so here we use a smaller one.\n",
    "initial_thetas = [0,0,0,0,0]\n",
    "\n",
    "thetas_list = data_test.gradient_descent( X, Y, alpha, 30000, type = 'linear' )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# linear ne testing\n",
    "\n",
    "data_test.get_ne(X,Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Longitudinal descent testing\n",
    "\n",
    "X = np.array([[1,9,5,4,3],[1,4,7,9,2],[1,7,5,8,6],[1,6,4,5,3],[1,8,6,11,7],[1,5,9,6,8],[1,7,4,10,6],[1,6,5,3,10]])\n",
    "Y = np.array([1,1,0,0,1,0,0,1])\n",
    "\n",
    "alpha = 0.05\n",
    "initial_thetas = [0,0,0,0,0]\n",
    "iterrations = 50000\n",
    "\n",
    "thetas_list = data_test.gradient_descent( X, Y, alpha, iterrations, type = 'log' )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "thetas_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# linear prediction\n",
    "import math\n",
    "\n",
    "\n",
    "X = np.array([\n",
    "    [1,4,2,1],\n",
    "    [1, 2,3.5,3],\n",
    "    [1,3,4,4],\n",
    "    [1,5,4,3],\n",
    "    [1,2,2,2]\n",
    "])\n",
    "\n",
    "# Given thetas\n",
    "thetas_list = [-10, 4, 3, -5]\n",
    "\n",
    "predictions = data_test.make_predictions(X, thetas_list, type = 'log')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions = data_test.make_predictions(X, thetas_list, type = 'linear')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "X = np.array([[1,9,5,4,3],[1,4,7,9,2],[1,7,5,8,6],[1,6,4,5,3],[1,8,6,11,7],[1,5,9,6,8],[1,7,4,10,6],[1,6,5,3,10]])\n",
    "Y = np.array([1,1,0,0,1,0,0,1])\n",
    "\n",
    "theta_list = data_test.gradient_descent( X, Y, alpha, iterrations, type = 'log' )\n",
    "print(theta_list)\n",
    "\n",
    "linear_cost = data_test.get_cost(theta_list, X, Y, 'log')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "method_list = [func for func in dir(data_test) if callable(getattr(data_test, func))]\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('general': conda)"
  },
  "interpreter": {
   "hash": "66fd99cc653260adf426bf328db08d1b55b377c06d9b72100938088d40231a18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}